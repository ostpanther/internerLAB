{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вариант с полной очисткой данных\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re \n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# очистка данных\n",
    "months = [\"Январ\", \"Феврал\", \"Март\", \"Апрел\", \"Ма\", \"Июн\", \"Июл\", \"Август\", \"Сентябр\", \"Октябр\", \"Ноябр\", \"Декабр\"]\n",
    "pattern = r'\\b(?:' + '|'.join([month + '[а-я]*' for month in months]) + r')\\b[.,]?' \n",
    "laws_links = []\n",
    "\n",
    "def remove_stops(text, stops):\n",
    "\n",
    "    text = re.sub(r'[а-яА-Я]\\)\\s', ' ', text) # удалить а), б) ...\n",
    "    text = re.sub(r'\\b[IVXLCDMivxlcdm]+\\b', '', text) # удалить все римские цифры\n",
    "    # text = re.sub(pattern, '', text, flags=re.IGNORECASE) # удалить месяцы\n",
    "    \n",
    "    #text = re.sub(r'\\bг\\.', '', text)\n",
    "    #text = re.sub(r'\\s\\d{1,2}\\.\\s|\\t\\d{1,2}\\.\\s', ' ', text) # удалить 1. 2. ...\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'№\\s', '№', text)# конкатенация №ФЗ123\n",
    "    text = re.sub(r'(\\t\\d\\s)|(\\s\\d\\s)|(\\s\\d\\t)', ' ', text)\n",
    "    text = re.sub('•|№', '', text) # удаление мусора по типу '•'\n",
    "\n",
    "    words = text.split()\n",
    "    final = []\n",
    "    final.append(' ')\n",
    "    for word in words: # удалить стоп-слова\n",
    "        if word not in stops:\n",
    "            final.append(word)\n",
    "    final = \" \".join(final) # склеить список из строк\n",
    "    final = final.translate(str.maketrans(\"\", \"\", string.punctuation)) # удалить пунктуацию\n",
    "    final = re.sub(r'(т\\sд)|(\\sт\\sд)|(\\sт\\s)|((\\sг\\s))', '', final)\n",
    "    \n",
    "    #закинем в конец дока ссылки на законы в документе (по другому никак если оставлять только их)\n",
    "    # z = text.split(' ')\n",
    "    # for ind, i in enumerate(z):\n",
    "    #     if '№' in i:\n",
    "    #         laws_links.append(i)\n",
    "            \n",
    "    \n",
    "    # final = \"\".join([i for i in final if not i.isdigit()]) # удалить все цифры\n",
    "    final = re.sub(r'\\t', ' ', final)\n",
    "    final = re.sub(r'\\s{1,}', ' ', final) # удалить много пробелов\n",
    "    \n",
    "    return (final)    \n",
    "\n",
    "\n",
    "def clean_docs(docs):\n",
    "    stops = stopwords.words('russian')\n",
    "    final_text = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        if i == 0 or i == 1:    # не трогать название документа\n",
    "            final_text.append(doc)\n",
    "        else:\n",
    "            clean_doc = remove_stops(doc, stops)\n",
    "            final_text.append(clean_doc)\n",
    "            \n",
    "    # if laws_links:\n",
    "    #     final_text.append('\\n')         \n",
    "    #     final_text.append(' '.join(laws_links))\n",
    "    \n",
    "    # laws_links.clear\n",
    "        \n",
    "    return (final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вариант очистки данных максимально приближенный к оригиналу \n",
    "import re \n",
    "import os\n",
    "\n",
    "# очистка данных\n",
    "\n",
    "def cleanser(text):\n",
    "\n",
    "    text = re.sub(r'\\t', ' ', text)\n",
    "    text = re.sub(r'№\\s', '№', text)# конкатенация №ФЗ123\n",
    "    text = re.sub(r'(\\t\\d\\s)|(\\s\\d\\s)|(\\s\\d\\t)', ' ', text)\n",
    "    text = re.sub('•|№', '', text) # удаление мусора по типу '•'    \n",
    "    \n",
    "    return (text)    \n",
    "\n",
    "\n",
    "def clean_docs(docs):\n",
    "    \n",
    "    final_text = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        if i == 0 or i == 1:    # не трогать название документа\n",
    "            final_text.append(doc)\n",
    "        else:\n",
    "            clean_doc = cleanser(doc)\n",
    "            final_text.append(clean_doc)\n",
    "\n",
    "    return (final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/Users/gleb/Desktop/InternetLab/internetlab/docs/row_docs/Стратегия_развития_информационного_общества_в_Российской_Федерации_на_2017_-_2030_годы.txt', 'r', encoding='utf-8')\n",
    "\n",
    "cleaned_docs = clean_docs(file)\n",
    "\n",
    "# запись в файл\n",
    "with open('/Users/gleb/Desktop/InternetLab/internetlab/docs//clean_docs/c_Стратегия_развития_информационного_общества_в_Российской_Федерации_на_2017_-_2030_годы.txt', \"w\", encoding=\"utf-8\") as d:\n",
    "    for i in cleaned_docs:\n",
    "        d.write(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка приближенных к оригиналу доков\n",
    "\n",
    "r_path = '/Users/gleb/Desktop/InternetLab/internetlab/docs/row_docs/'\n",
    "c_path = '/Users/gleb/Desktop/InternetLab/internetlab/docs//clean_docs/'\n",
    "\n",
    "raw_doc_list = os.listdir(r_path)\n",
    "clean_doc_list = os.listdir(c_path)\n",
    "for doc in raw_doc_list:\n",
    "    if '.txt' in doc:\n",
    "        file  = open(os.path.join(r_path, doc), 'r', encoding='utf-8')\n",
    "        cleaned_docs = clean_docs(file)\n",
    "        # запись в файл\n",
    "        for c_doc in clean_doc_list:\n",
    "            document = os.path.join(c_path, 'c_' + doc)\n",
    "            with open(document, \"w\", encoding=\"utf-8\") as d:\n",
    "                for i in cleaned_docs:\n",
    "                    d.write(i)\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка  полностью очищеных доков\n",
    "\n",
    "r_path = '/Users/gleb/Desktop/InternetLab/internetlab/docs/row_docs/raw_fed'\n",
    "c_path = '/Users/gleb/Desktop/InternetLab/internetlab/docs/clean_docs/fed_clean/fed_full_clean'\n",
    "\n",
    "raw_doc_list = os.listdir(r_path)\n",
    "clean_doc_list = os.listdir(c_path)\n",
    "for doc in raw_doc_list:\n",
    "    if '.txt' in doc:\n",
    "        file  = open(os.path.join(r_path, doc), 'r', encoding='utf-8')\n",
    "        cleaned_docs = clean_docs(file)\n",
    "        # запись в файл\n",
    "    \n",
    "        document = os.path.join(c_path, 'fc_' + doc)\n",
    "        with open(document, \"w\", encoding=\"utf-8\") as d:\n",
    "            for i in cleaned_docs:\n",
    "                d.write(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запись в Json\n",
    "json_path = '/Users/gleb/Desktop/InternetLab/internetlab/docs/clean_docs/clean_fed.json'\n",
    "folder_path = '/Users/gleb/Desktop/InternetLab/internetlab/docs/clean_docs/fed_clean/fed_full_clean'\n",
    "\n",
    "# Создаем пустые списки для названий документов и текста\n",
    "titles = []\n",
    "texts = []\n",
    "\n",
    "# Перебираем файлы в папке 'fed_full_clean'\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
    "            lines = file.readlines()\n",
    "            if len(lines) >= 3:  # Убеждаемся, что в файле достаточно строк\n",
    "                titles.append(lines[0].strip())  # Добавляем название документа из первой строки\n",
    "                texts.append(lines[2].strip())  # Добавляем текст из третьей строки\n",
    "\n",
    "# Создаем словарь с названиями документов и текстом\n",
    "data = {\n",
    "    \"title\": titles,\n",
    "    \"text\": texts\n",
    "}\n",
    "\n",
    "# Записываем данные в JSON файл\n",
    "with open(json_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(data, json_file, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
